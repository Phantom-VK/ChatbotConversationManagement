{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "9gPRrq8PGjJb",
        "b4_fU74jJ66f",
        "1ctXTVPmP8Fq",
        "6uTVD5n3eVyy",
        "f7t-lgDqeZq2",
        "s4Cge2reedr-",
        "TxuCIaXwGg1J",
        "tnvwOw6CG5i-",
        "K3yTmfOHID7k",
        "Lo83zaogIyKV",
        "FBQf-HSCJ4Ws",
        "3Yo043fbK0z5",
        "hd7l3d_nK4Rt",
        "CvA01nyZYASu",
        "IS6xIFOLZLc0"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Downloads and Imports**"
      ],
      "metadata": {
        "id": "9gPRrq8PGjJb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "BD0QavPNFhcp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0832031-8f54-4b31-880f-dc5d9e6d99d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/331.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m331.1/331.1 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install --quiet requests openai jsonschema pydantic[email]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from openai import OpenAI\n",
        "from google.colab import userdata\n",
        "from typing import List, Dict, Literal"
      ],
      "metadata": {
        "id": "bXXbMbfVH7BS"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Configurations and Model Instances**"
      ],
      "metadata": {
        "id": "b4_fU74jJ66f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CHAT_MODEL = \"llama-3.3-70b-versatile\"\n",
        "STRUCTURED_OUTPUT_MODEL = \"openai/gpt-oss-20b\""
      ],
      "metadata": {
        "id": "C0MEJ6f1LM4M"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client = OpenAI(\n",
        "    base_url=\"https://api.groq.com/openai/v1\",\n",
        "    api_key = userdata.get(\"GROQ_API_KEY\")\n",
        ")"
      ],
      "metadata": {
        "id": "AyNdxjW7J-Dt"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Task 1: Managing Conversation History with Summarization**\n",
        "\n",
        "- Message History Tracking\n",
        "- Summarization\n",
        "- Truncation"
      ],
      "metadata": {
        "id": "1ctXTVPmP8Fq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MESSAGE_HISTORY : List[dict] = []\n",
        "SUMMARY = \"\""
      ],
      "metadata": {
        "id": "fUIAOVyVqQ90"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function to add messages"
      ],
      "metadata": {
        "id": "6uTVD5n3eVyy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "summarization_interval = 8\n",
        "turn_count = 0\n",
        "def add_message(message):\n",
        "    global turn_count\n",
        "    role = message['role']\n",
        "    MESSAGE_HISTORY.append(message)\n",
        "    turn_count += 1\n",
        "    print(f\"Turn {turn_count}: Added {message}\")\n",
        "\n",
        "    if turn_count % summarization_interval == 0:\n",
        "      print(f\"Turn count {turn_count}, output: {turn_count % summarization_interval}\")\n",
        "      periodic_summarization()"
      ],
      "metadata": {
        "id": "ydfk_B0OP_br"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## functionm to create summary"
      ],
      "metadata": {
        "id": "f7t-lgDqeZq2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_summary(messages):\n",
        "    global SUMMARY\n",
        "    global turn_count\n",
        "    global MESSAGE_HISTORY\n",
        "\n",
        "    if not MESSAGE_HISTORY:\n",
        "        print(\"No messages to summarize.\")\n",
        "        return\n",
        "    conversation_text = \"\\n\".join([f\"{message['role']}: {message['content']}\" for message in MESSAGE_HISTORY])\n",
        "\n",
        "    summary_prompt = f\"\"\"\n",
        "        Please provide a concise summary of the following conversation, in the third person point of view. Focus on:\n",
        "        1. Main topics discussed\n",
        "        2. Key decisions or outcomes\n",
        "        3. Important information exchanged\n",
        "        4. Overall context and flow\n",
        "\n",
        "        Conversation:\n",
        "        {conversation_text}\n",
        "\n",
        "        Summary:\"\"\"\n",
        "    try:\n",
        "        chat_bot_response = client.chat.completions.create(\n",
        "          model=CHAT_MODEL,\n",
        "            messages=[{\"role\":\"user\", \"content\":conversation_text}],\n",
        "            max_tokens=150,\n",
        "            temperature=0.3)\n",
        "        summary = chat_bot_response.choices[0].message.content.strip()\n",
        "        print(f\"✅ Generated summary ({len(summary)} characters)\")\n",
        "        return summary\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error generating summary: {e}\")\n",
        "        return \"Summary generation failed\""
      ],
      "metadata": {
        "id": "P_io4vKcWO6E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function to create periodic summary"
      ],
      "metadata": {
        "id": "s4Cge2reedr-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def periodic_summarization():\n",
        "        global MESSAGE_HISTORY\n",
        "        global SUMMARY\n",
        "\n",
        "        # Only generate a new summary if there's enough new conversation\n",
        "        if len(MESSAGE_HISTORY) >= 2:\n",
        "            current_summary = generate_summary(MESSAGE_HISTORY)\n",
        "\n",
        "            if SUMMARY:\n",
        "                # Combine with previous summary\n",
        "                combined_prompt = f\"\"\"\n",
        "                Previous summary: {SUMMARY}\n",
        "\n",
        "                New conversation summary: {current_summary}\n",
        "\n",
        "                Please create a comprehensive summary that combines both:\"\"\"\n",
        "\n",
        "                try:\n",
        "                    response = client.chat.completions.create(\n",
        "                        model=CHAT_MODEL,\n",
        "                        messages=[{\"role\": \"user\", \"content\": combined_prompt}],\n",
        "                        max_tokens= 300,\n",
        "                        temperature=0.3\n",
        "                    )\n",
        "\n",
        "                    SUMMARY = response.choices[0].message.content.strip()\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"❌ Error combining summaries: {e}\")\n",
        "                    SUMMARY = current_summary\n",
        "            else:\n",
        "                SUMMARY = current_summary\n",
        "\n",
        "            # Replace history with summary\n",
        "            MESSAGE_HISTORY = [\n",
        "                {\"role\": \"system\", \"content\": CHAT_MODEL_SYSTEM_PROMPT},\n",
        "                {\"role\": \"system\", \"content\": f\"Previous conversation summary: {SUMMARY}\"}\n",
        "            ]\n",
        "\n",
        "            print(f\"Conversation summarized and history reset\")\n",
        "            print(f\"Current summary length: {len(SUMMARY)} characters\")"
      ],
      "metadata": {
        "id": "kkFgwJ8XezA2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Helper Functions"
      ],
      "metadata": {
        "id": "TxuCIaXwGg1J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def count_words(text: str) -> int:\n",
        "    return len(text.split())\n",
        "\n",
        "def count_characters(messages: List[Dict]) -> int:\n",
        "    return sum(len(msg[\"content\"]) for msg in messages)\n",
        "\n",
        "def count_total_words(messages: List[Dict]) -> int:\n",
        "    return sum(count_words(msg[\"content\"]) for msg in messages)"
      ],
      "metadata": {
        "id": "LIu7myvAGgVv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function to truncate conversation by turns"
      ],
      "metadata": {
        "id": "tnvwOw6CG5i-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_turns = 6\n",
        "def truncate_by_turns(messages: List[Dict]) -> List[Dict]:\n",
        "  if max_turns and len(messages) > max_turns:\n",
        "      truncated = messages[-max_turns:]\n",
        "      print(f\"Truncated to last {max_turns} messages\")\n",
        "      return truncated\n",
        "  return messages"
      ],
      "metadata": {
        "id": "pE0WOBZKHAua"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Truncate by length"
      ],
      "metadata": {
        "id": "K3yTmfOHID7k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_characters = 300\n",
        "max_words = 80\n",
        "def truncate_by_length(messages: List[Dict]) -> List[Dict]:\n",
        "    if not (max_characters or max_words):\n",
        "        return messages\n",
        "\n",
        "    result = []\n",
        "    current_chars = 0\n",
        "    current_words = 0\n",
        "\n",
        "    # Start from the end to keep most recent messages\n",
        "    for message in reversed(messages):\n",
        "        msg_chars = len(message[\"content\"])\n",
        "        msg_words = count_words(message[\"content\"])\n",
        "\n",
        "        # Check if adding this message would exceed limits\n",
        "        if (max_characters and current_chars + msg_chars > max_characters) or (max_words and current_words + msg_words > max_words):\n",
        "            break\n",
        "\n",
        "        result.insert(0, message)\n",
        "        current_chars += msg_chars\n",
        "        current_words += msg_words\n",
        "\n",
        "    if len(result) < len(messages):\n",
        "        removed = len(messages) - len(result)\n",
        "        print(f\"📝 Truncated {removed} messages due to length constraints\")\n",
        "\n",
        "    return result"
      ],
      "metadata": {
        "id": "7bbJJTIcIGaL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get truncated history"
      ],
      "metadata": {
        "id": "Lo83zaogIyKV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_truncated_history(trunc_type:str) -> List[Dict]:\n",
        "        messages = MESSAGE_HISTORY.copy()\n",
        "        if not trunc_type:\n",
        "          raise ValueError(\"Truncation type not provided\")\n",
        "\n",
        "        # Apply truncation strategies\n",
        "        if trunc_type == \"turns\":\n",
        "          return truncate_by_turns(messages)\n",
        "\n",
        "        return truncate_by_length(messages)"
      ],
      "metadata": {
        "id": "MtFHLPzhI0c0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get overall, used parameters"
      ],
      "metadata": {
        "id": "FBQf-HSCJ4Ws"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_statistics() -> Dict:\n",
        "    \"\"\"Get detailed statistics about the conversation.\"\"\"\n",
        "    stats = {\n",
        "            \"total_turns\": turn_count,\n",
        "            \"current_messages\": len(MESSAGE_HISTORY),\n",
        "            \"total_characters\": count_characters(MESSAGE_HISTORY),\n",
        "            \"total_words\": count_total_words(MESSAGE_HISTORY),\n",
        "            \"has_summary\": bool(SUMMARY),\n",
        "            \"summary_length\": len(SUMMARY) if SUMMARY else 0,\n",
        "            \"summarization_interval\": summarization_interval,\n",
        "            \"truncation_limits\": {\n",
        "                \"max_turns\": max_turns,\n",
        "                \"max_characters\": max_characters,\n",
        "                \"max_words\": max_words\n",
        "            }\n",
        "        }\n",
        "    return stats"
      ],
      "metadata": {
        "id": "_1LqAAA9J9dl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_statistics()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7JOvYwVvKQQ7",
        "outputId": "c3b15e6c-96f6-4b3a-a151-0de9c8b9a8be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'total_turns': 0,\n",
              " 'current_messages': 8,\n",
              " 'total_characters': 1676,\n",
              " 'total_words': 279,\n",
              " 'has_summary': True,\n",
              " 'summary_length': 969,\n",
              " 'summarization_interval': 8,\n",
              " 'truncation_limits': {'max_turns': 6, 'max_characters': 300, 'max_words': 80}}"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Test Conversation Manager**"
      ],
      "metadata": {
        "id": "p4pUiT_Sev_J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Try Conversation with LLM"
      ],
      "metadata": {
        "id": "3Yo043fbK0z5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "    user_input = input(\"User: \")\n",
        "    add_message({\"role\": \"user\", \"content\": user_input})\n",
        "\n",
        "    try:\n",
        "        chat_bot_response = client.chat.completions.create(\n",
        "            model=CHAT_MODEL,\n",
        "            messages=MESSAGE_HISTORY\n",
        "        )\n",
        "        response_content = chat_bot_response.choices[0].message.content\n",
        "        add_message({\"role\": \"assistant\", \"content\": response_content})\n",
        "\n",
        "        print(f\"Bot: {response_content}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")"
      ],
      "metadata": {
        "id": "kc8J6W-8R7-g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pbhqZoMjAM9Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test with test message jsons"
      ],
      "metadata": {
        "id": "hd7l3d_nK4Rt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "conversation_samples = [\n",
        "        (\"user\", \"Hello! I'm looking for advice on starting a small business.\"),\n",
        "        (\"assistant\", \"Great! I'd be happy to help. What type of business are you considering?\"),\n",
        "        (\"user\", \"I'm thinking about opening a coffee shop in downtown Seattle.\"),\n",
        "        (\"assistant\", \"Excellent choice! Seattle has a great coffee culture. Have you done any market research?\"),\n",
        "        (\"user\", \"Not yet. Where should I start with market research?\"),\n",
        "        (\"assistant\", \"I recommend starting with competitor analysis, foot traffic studies, and customer surveys.\"),\n",
        "        (\"user\", \"That sounds comprehensive. What about financing options?\"),\n",
        "        (\"assistant\", \"For coffee shops, you have several options: SBA loans, traditional bank loans, investors, or crowdfunding.\")\n",
        "    ]"
      ],
      "metadata": {
        "id": "Sv4vAGdYK_e0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Clear previous history for a clean test\n",
        "MESSAGE_HISTORY = []\n",
        "turn_count = 0\n",
        "SUMMARY = \"\"\n",
        "\n",
        "print(\"--- Testing Truncation ---\")\n",
        "\n",
        "# fill message history with sample conversation\n",
        "for role, content in conversation_samples:\n",
        "    add_message({\"role\": role, \"content\": content})\n",
        "\n",
        "print(\"\\n--- Original Message History ---\")\n",
        "for msg in MESSAGE_HISTORY:\n",
        "    print(f\"{msg['role']}: {msg['content']}\")\n",
        "print(f\"Total messages: {len(MESSAGE_HISTORY)}\")\n",
        "\n",
        "print(\"\\n--- Truncating by Turns (max_turns=6) ---\")\n",
        "truncated_by_turns = get_truncated_history(trunc_type=\"turns\")\n",
        "for msg in truncated_by_turns:\n",
        "    print(f\"{msg['role']}: {msg['content']}\")\n",
        "print(f\"Truncated messages: {len(truncated_by_turns)}\")\n",
        "\n",
        "\n",
        "print(\"\\n--- Truncating by Length (max_characters=300, max_words=80) ---\")\n",
        "truncated_by_length = get_truncated_history(trunc_type=\"length\")\n",
        "for msg in truncated_by_length:\n",
        "    print(f\"{msg['role']}: {msg['content']}\")\n",
        "print(f\"Truncated messages: {len(truncated_by_length)}\")\n",
        "\n",
        "print(\"\\n--- Truncation Test Complete ---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E880Q_grLBj0",
        "outputId": "47cfd891-5259-4b33-a5b6-7a147cc8e3ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Testing Truncation ---\n",
            "Turn 1: Added {'role': 'user', 'content': \"Hello! I'm looking for advice on starting a small business.\"}\n",
            "Turn 2: Added {'role': 'assistant', 'content': \"Great! I'd be happy to help. What type of business are you considering?\"}\n",
            "Turn 3: Added {'role': 'user', 'content': \"I'm thinking about opening a coffee shop in downtown Seattle.\"}\n",
            "Turn 4: Added {'role': 'assistant', 'content': 'Excellent choice! Seattle has a great coffee culture. Have you done any market research?'}\n",
            "Turn 5: Added {'role': 'user', 'content': 'Not yet. Where should I start with market research?'}\n",
            "Turn 6: Added {'role': 'assistant', 'content': 'I recommend starting with competitor analysis, foot traffic studies, and customer surveys.'}\n",
            "Turn 7: Added {'role': 'user', 'content': 'That sounds comprehensive. What about financing options?'}\n",
            "Turn 8: Added {'role': 'assistant', 'content': 'For coffee shops, you have several options: SBA loans, traditional bank loans, investors, or crowdfunding.'}\n",
            "Turn count 8, output: 0\n",
            "✅ Generated summary (615 characters)\n",
            "Conversation summarized and history reset\n",
            "Current summary length: 615 characters\n",
            "\n",
            "--- Original Message History ---\n",
            "system: \n",
            "\n",
            "\n",
            "system: Previous conversation summary: It's great that you're thinking about financing options early on. Additionally, you may also want to consider alternative lenders, small business grants, or even partnering with a business incubator. It's also important to create a solid business plan, including a detailed budget, revenue projections, and a marketing strategy. This will help you secure funding and make informed decisions as you move forward. \n",
            "\n",
            "Have you thought about what will set your coffee shop apart from the existing ones in downtown Seattle? What unique features, products, or services do you plan to offer to attract and retain customers?\n",
            "Total messages: 2\n",
            "\n",
            "--- Truncating by Turns (max_turns=6) ---\n",
            "system: \n",
            "\n",
            "\n",
            "system: Previous conversation summary: It's great that you're thinking about financing options early on. Additionally, you may also want to consider alternative lenders, small business grants, or even partnering with a business incubator. It's also important to create a solid business plan, including a detailed budget, revenue projections, and a marketing strategy. This will help you secure funding and make informed decisions as you move forward. \n",
            "\n",
            "Have you thought about what will set your coffee shop apart from the existing ones in downtown Seattle? What unique features, products, or services do you plan to offer to attract and retain customers?\n",
            "Truncated messages: 2\n",
            "\n",
            "--- Truncating by Length (max_characters=300, max_words=80) ---\n",
            "📝 Truncated 2 messages due to length constraints\n",
            "Truncated messages: 0\n",
            "\n",
            "--- Truncation Test Complete ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5tyL3Oq9LjQF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Task 2: JSON Schema Classification & Information Extraction**"
      ],
      "metadata": {
        "id": "CvA01nyZYASu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Required JSON Schemas and Prompts"
      ],
      "metadata": {
        "id": "IS6xIFOLZLc0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic import BaseModel, EmailStr\n",
        "from typing import List, Dict, Literal, Optional\n",
        "\n",
        "class UserInformationModel(BaseModel):\n",
        "    name: Optional[str] = None\n",
        "    email: Optional[EmailStr] = None\n",
        "    phone: Optional[str] = None\n",
        "    location: Optional[str] = None\n",
        "    age: Optional[int] = None\n",
        "    tech_stack: Optional[List[str]] = None"
      ],
      "metadata": {
        "id": "L8FwfVZBYGWX"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SYSTEM_PROMPT = system_prompt = \"\"\"You are an expert information extractor. Your task is to carefully analyze chat conversations and extract specific user information when available.\n",
        "\n",
        "\n",
        "FOLLOW THESE IMPORTANT GUIDELINES:\n",
        "1. Extract only information that is explicitly mentioned in the conversation\n",
        "2. Do not make assumptions or infer information not directly stated\n",
        "3. For names: Extract full names when provided\n",
        "4. For emails: Look for email addresses in standard formats, should contain '@'\n",
        "5. For phones: Extract any phone number mentioned (any format, should be 10 digit)\n",
        "6. For locations: Extract cities, states, addresses, or geographical references\n",
        "7. For age: Extract numerical age when mentioned\n",
        "8. For tech_stack: Extract a list of technical skills when mentioned\n",
        "\n",
        "Cross check all information before giving an output.\n",
        "\n",
        "If information is not clearly given, leave that field empty instead of guessing.\"\"\""
      ],
      "metadata": {
        "id": "l74lmwFgYdLi"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function to extract information"
      ],
      "metadata": {
        "id": "p5cdHC6JfLDo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_information(chat_conversation: str | List[Dict]) -> dict:\n",
        "\n",
        "  USER_PROMPT = f\"\"\"Please extract any available user information from this chat conversation:\n",
        "\n",
        "{chat_conversation}\n",
        "\n",
        "Use the extract_user_information function to provide the structured output.\"\"\"\n",
        "  try:\n",
        "      chat_bot_response = client.chat.completions.create(\n",
        "            model=STRUCTURED_OUTPUT_MODEL,\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
        "                {\"role\":\"user\", \"content\":USER_PROMPT},\n",
        "            ],\n",
        "            response_format =  {\n",
        "                \"type\": \"json_schema\",\n",
        "                \"json_schema\":{\n",
        "                    \"name\":\"user_information\",\n",
        "                    \"description\":\"User information extracted from the chat conversation\",\n",
        "                    \"schema\":UserInformationModel.model_json_schema()\n",
        "\n",
        "                } }\n",
        "        )\n",
        "      return chat_bot_response.choices[0].message.content\n",
        "  except Exception as e:\n",
        "    raise Exception(f\"Error extracting information: {e}\")"
      ],
      "metadata": {
        "id": "xt8sIJ5PfPEA"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test Information Extraction"
      ],
      "metadata": {
        "id": "k5dMfgn5nmpT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SAMPLE_CHATS = [\n",
        "    # Sample 1: Customer support chat with complete information, including tech stack\n",
        "    \"\"\"Customer: Hi, I'm having trouble with my order\n",
        "Agent: I'd be happy to help! Can I get your name and email?\n",
        "Customer: Sure, it's Sarah Johnson and my email is sarah.johnson@email.com\n",
        "Agent: Thank you Sarah. Can I also get your phone number and address?\n",
        "Customer: Yes, my phone is (555) 123-4567 and I live in Seattle, WA. I'm 28 years old by the way, does that matter for shipping?\n",
        "Agent: Thank you for all that information! Just to confirm, what tech do you use the most?\n",
        "Customer: Mostly Python and Django for my small business website.\n",
        "Agent: Let me look up your order.\"\"\",\n",
        "\n",
        "    # Sample 2: Registration chat with partial information & tech stack\n",
        "    \"\"\"User: I want to sign up for your newsletter\n",
        "Bot: Great! What's your email address?\n",
        "User: It's mike.chen@company.com\n",
        "Bot: Thanks! And your name?\n",
        "User: Mike Chen\n",
        "Bot: Any location preference for local events?\n",
        "User: I'm based in San Francisco.\n",
        "Bot: Do you use any specific tech tools or frameworks at work?\n",
        "User: Node.js and React.\n",
        "Bot: Perfect, you're all set!\"\"\",\n",
        "\n",
        "    # Sample 3: Survey chat with mixed information\n",
        "    \"\"\"Interviewer: Thank you for participating in our survey. Could you share some basic information?\n",
        "Participant: Of course\n",
        "Interviewer: What's your name and age?\n",
        "Participant: I'm Jennifer Davis, 35 years old\n",
        "Interviewer: Great! Do you have a preferred contact method?\n",
        "Participant: You can reach me at jennifer.davis.work@gmail.com or call me at 555-987-6543\n",
        "Interviewer: And which city are you located in?\n",
        "Participant: I live in Austin, Texas\n",
        "Interviewer: Do you work in any particular technology area?\n",
        "Participant: Yes, mainly with AWS, Java, and Docker.\n",
        "Interviewer: Perfect, that's all we need!\"\"\",\n",
        "\n",
        "    # Sample 4: Job application chat with multiple tech skills\n",
        "    \"\"\"Recruiter: Welcome, could you please tell me your name and how to reach you?\n",
        "Candidate: My name is Priya Sharma. You can email me at priya.sharma123@gmail.com.\n",
        "Recruiter: And your phone number and current location?\n",
        "Candidate: Sure, my phone is +91-9876543210, and I'm currently in Bengaluru.\n",
        "Recruiter: What's your age and primary tech stacks?\n",
        "Candidate: I'm 25. I primarily work with Vue.js, FastAPI, and PostgreSQL.\n",
        "Recruiter: Noted. Do you have experience with cloud platforms?\n",
        "Candidate: Yes, GCP and Azure are part of my daily workflow.\"\"\",\n",
        "\n",
        "    # Sample 5: Casual onboarding chat with partial information\n",
        "    \"\"\"Mentor: Hi! Welcome aboard. What's your full name?\n",
        "Newcomer: I'm Alex Martinez.\n",
        "Mentor: Great, Alex. You can share your contact details when you're ready.\n",
        "Newcomer: Sure! My email: alexmartinez@startup.io\n",
        "Mentor: Where are you joining from?\n",
        "Newcomer: I'm based in Boston. I usually build with Flutter and Firebase.\n",
        "Mentor: Awesome! Age is optional, but it helps with mentorship pairing.\n",
        "Newcomer: I'm 30.\n",
        "Mentor: Thanks, Alex. Let's start!\"\"\"\n",
        "]"
      ],
      "metadata": {
        "id": "pBTLdEbLgj1F"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"--- Testing Information Extraction with Sample Chats ---\")\n",
        "\n",
        "for i, chat in enumerate(SAMPLE_CHATS):\n",
        "    print(f\"\\n--- Sample Chat {i+1} ---\")\n",
        "    print(chat)\n",
        "    try:\n",
        "        extracted_data_json = extract_information(chat)\n",
        "\n",
        "        extracted_data = json.loads(extracted_data_json)\n",
        "        validated_data = UserInformation.model_validate(extracted_data)\n",
        "        print(\"\\n✅ Extracted and Validated Information:\")\n",
        "        print(validated_data.model_dump_json(indent=2))\n",
        "    except Exception as e:\n",
        "        print(f\"\\n❌ Error processing sample chat {i+1}: {e}\")\n",
        "\n",
        "print(\"\\n--- Information Extraction Test Complete ---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IhF8SSq5nWI3",
        "outputId": "ffb5fd50-7ace-4910-c6d5-df9fab18b3c3"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Testing Information Extraction with Sample Chats ---\n",
            "\n",
            "--- Sample Chat 1 ---\n",
            "Customer: Hi, I'm having trouble with my order\n",
            "Agent: I'd be happy to help! Can I get your name and email?\n",
            "Customer: Sure, it's Sarah Johnson and my email is sarah.johnson@email.com\n",
            "Agent: Thank you Sarah. Can I also get your phone number and address?\n",
            "Customer: Yes, my phone is (555) 123-4567 and I live in Seattle, WA. I'm 28 years old by the way, does that matter for shipping?\n",
            "Agent: Thank you for all that information! Just to confirm, what tech do you use the most?\n",
            "Customer: Mostly Python and Django for my small business website.\n",
            "Agent: Let me look up your order.\n",
            "\n",
            "✅ Extracted and Validated Information:\n",
            "{\n",
            "  \"name\": \"Sarah Johnson\",\n",
            "  \"email\": \"sarah.johnson@email.com\",\n",
            "  \"phone\": \"(555) 123-4567\",\n",
            "  \"location\": \"Seattle, WA\",\n",
            "  \"age\": 28,\n",
            "  \"tech_stack\": [\n",
            "    \"Python\",\n",
            "    \"Django\"\n",
            "  ]\n",
            "}\n",
            "\n",
            "--- Sample Chat 2 ---\n",
            "User: I want to sign up for your newsletter\n",
            "Bot: Great! What's your email address?\n",
            "User: It's mike.chen@company.com\n",
            "Bot: Thanks! And your name?\n",
            "User: Mike Chen\n",
            "Bot: Any location preference for local events?\n",
            "User: I'm based in San Francisco.\n",
            "Bot: Do you use any specific tech tools or frameworks at work?\n",
            "User: Node.js and React.\n",
            "Bot: Perfect, you're all set!\n",
            "\n",
            "✅ Extracted and Validated Information:\n",
            "{\n",
            "  \"name\": \"Mike Chen\",\n",
            "  \"email\": \"mike.chen@company.com\",\n",
            "  \"phone\": null,\n",
            "  \"location\": \"San Francisco\",\n",
            "  \"age\": null,\n",
            "  \"tech_stack\": [\n",
            "    \"Node.js\",\n",
            "    \"React\"\n",
            "  ]\n",
            "}\n",
            "\n",
            "--- Sample Chat 3 ---\n",
            "Interviewer: Thank you for participating in our survey. Could you share some basic information?\n",
            "Participant: Of course\n",
            "Interviewer: What's your name and age?\n",
            "Participant: I'm Jennifer Davis, 35 years old\n",
            "Interviewer: Great! Do you have a preferred contact method?\n",
            "Participant: You can reach me at jennifer.davis.work@gmail.com or call me at 555-987-6543\n",
            "Interviewer: And which city are you located in?\n",
            "Participant: I live in Austin, Texas\n",
            "Interviewer: Do you work in any particular technology area?\n",
            "Participant: Yes, mainly with AWS, Java, and Docker.\n",
            "Interviewer: Perfect, that's all we need!\n",
            "\n",
            "✅ Extracted and Validated Information:\n",
            "{\n",
            "  \"name\": \"Jennifer Davis\",\n",
            "  \"email\": \"jennifer.davis.work@gmail.com\",\n",
            "  \"phone\": \"555-987-6543\",\n",
            "  \"location\": \"Austin, Texas\",\n",
            "  \"age\": 35,\n",
            "  \"tech_stack\": [\n",
            "    \"AWS\",\n",
            "    \"Java\",\n",
            "    \"Docker\"\n",
            "  ]\n",
            "}\n",
            "\n",
            "--- Sample Chat 4 ---\n",
            "Recruiter: Welcome, could you please tell me your name and how to reach you?\n",
            "Candidate: My name is Priya Sharma. You can email me at priya.sharma123@gmail.com.\n",
            "Recruiter: And your phone number and current location?\n",
            "Candidate: Sure, my phone is +91-9876543210, and I'm currently in Bengaluru.\n",
            "Recruiter: What's your age and primary tech stacks?\n",
            "Candidate: I'm 25. I primarily work with Vue.js, FastAPI, and PostgreSQL.\n",
            "Recruiter: Noted. Do you have experience with cloud platforms?\n",
            "Candidate: Yes, GCP and Azure are part of my daily workflow.\n",
            "\n",
            "✅ Extracted and Validated Information:\n",
            "{\n",
            "  \"name\": \"Priya Sharma\",\n",
            "  \"email\": \"priya.sharma123@gmail.com\",\n",
            "  \"phone\": \"+91-9876543210\",\n",
            "  \"location\": \"Bengaluru\",\n",
            "  \"age\": 25,\n",
            "  \"tech_stack\": [\n",
            "    \"Vue.js\",\n",
            "    \"FastAPI\",\n",
            "    \"PostgreSQL\"\n",
            "  ]\n",
            "}\n",
            "\n",
            "--- Sample Chat 5 ---\n",
            "Mentor: Hi! Welcome aboard. What's your full name?\n",
            "Newcomer: I'm Alex Martinez.\n",
            "Mentor: Great, Alex. You can share your contact details when you're ready.\n",
            "Newcomer: Sure! My email: alexmartinez@startup.io\n",
            "Mentor: Where are you joining from?\n",
            "Newcomer: I'm based in Boston. I usually build with Flutter and Firebase.\n",
            "Mentor: Awesome! Age is optional, but it helps with mentorship pairing.\n",
            "Newcomer: I'm 30.\n",
            "Mentor: Thanks, Alex. Let's start!\n",
            "\n",
            "✅ Extracted and Validated Information:\n",
            "{\n",
            "  \"name\": \"Alex Martinez\",\n",
            "  \"email\": \"alexmartinez@startup.io\",\n",
            "  \"phone\": null,\n",
            "  \"location\": \"Boston\",\n",
            "  \"age\": 30,\n",
            "  \"tech_stack\": [\n",
            "    \"Flutter\",\n",
            "    \"Firebase\"\n",
            "  ]\n",
            "}\n",
            "\n",
            "--- Information Extraction Test Complete ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VghoFaK9pgXF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}