{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "9gPRrq8PGjJb",
        "b4_fU74jJ66f",
        "6uTVD5n3eVyy",
        "f7t-lgDqeZq2",
        "s4Cge2reedr-",
        "TxuCIaXwGg1J",
        "tnvwOw6CG5i-",
        "K3yTmfOHID7k",
        "Lo83zaogIyKV",
        "FBQf-HSCJ4Ws",
        "3Yo043fbK0z5",
        "hd7l3d_nK4Rt"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Downloads and Imports**"
      ],
      "metadata": {
        "id": "9gPRrq8PGjJb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BD0QavPNFhcp"
      },
      "outputs": [],
      "source": [
        "!pip install --quiet requests openai jsonschema"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from openai import OpenAI\n",
        "from google.colab import userdata\n",
        "from typing import List, Dict"
      ],
      "metadata": {
        "id": "bXXbMbfVH7BS"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Configurations, Model Instances and Constans**"
      ],
      "metadata": {
        "id": "b4_fU74jJ66f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CHAT_MODEL = \"llama-3.3-70b-versatile\"\n",
        "STRUCTURED_OUTPUT_MODEL = \"openai/gpt-oss-20b\""
      ],
      "metadata": {
        "id": "C0MEJ6f1LM4M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client = OpenAI(\n",
        "    base_url=\"https://api.groq.com/openai/v1\",\n",
        "    api_key = userdata.get(\"GROQ_API_KEY\")\n",
        ")"
      ],
      "metadata": {
        "id": "AyNdxjW7J-Dt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MESSAGE_HISTORY : List[dict] = []"
      ],
      "metadata": {
        "id": "EqogJWocNBP2"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SUMMARY = \"\""
      ],
      "metadata": {
        "id": "FUDq_20SQn_-"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CHAT_MODEL_SYSTEM_PROMPT = \"\"\"\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "fJ8EgtlGSK4B"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conversation Manager Utilities**"
      ],
      "metadata": {
        "id": "1ctXTVPmP8Fq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function to add messages"
      ],
      "metadata": {
        "id": "6uTVD5n3eVyy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "summarization_interval = 8\n",
        "turn_count = 0\n",
        "def add_message(message):\n",
        "    global turn_count\n",
        "    role = message['role']\n",
        "    MESSAGE_HISTORY.append(message)\n",
        "    turn_count += 1\n",
        "    print(f\"Turn {turn_count}: Added {message}\")\n",
        "\n",
        "    if turn_count % summarization_interval == 0:\n",
        "      print(f\"Turn count {turn_count}, output: {turn_count % summarization_interval}\")\n",
        "      periodic_summarization()"
      ],
      "metadata": {
        "id": "ydfk_B0OP_br"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## functionm to create summary"
      ],
      "metadata": {
        "id": "f7t-lgDqeZq2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_summary(messages):\n",
        "    global SUMMARY\n",
        "    global turn_count\n",
        "    global MESSAGE_HISTORY\n",
        "\n",
        "    if not MESSAGE_HISTORY:\n",
        "        print(\"No messages to summarize.\")\n",
        "        return\n",
        "    conversation_text = \"\\n\".join([f\"{message['role']}: {message['content']}\" for message in MESSAGE_HISTORY])\n",
        "\n",
        "    summary_prompt = f\"\"\"\n",
        "        Please provide a concise summary of the following conversation, in the third person point of view. Focus on:\n",
        "        1. Main topics discussed\n",
        "        2. Key decisions or outcomes\n",
        "        3. Important information exchanged\n",
        "        4. Overall context and flow\n",
        "\n",
        "        Conversation:\n",
        "        {conversation_text}\n",
        "\n",
        "        Summary:\"\"\"\n",
        "    try:\n",
        "        chat_bot_response = client.chat.completions.create(\n",
        "          model=CHAT_MODEL,\n",
        "            messages=[{\"role\":\"user\", \"content\":conversation_text}],\n",
        "            max_tokens=150,\n",
        "            temperature=0.3)\n",
        "        summary = chat_bot_response.choices[0].message.content.strip()\n",
        "        print(f\"‚úÖ Generated summary ({len(summary)} characters)\")\n",
        "        return summary\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error generating summary: {e}\")\n",
        "        return \"Summary generation failed\""
      ],
      "metadata": {
        "id": "P_io4vKcWO6E"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function to create periodic summary"
      ],
      "metadata": {
        "id": "s4Cge2reedr-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def periodic_summarization():\n",
        "        global MESSAGE_HISTORY\n",
        "        global SUMMARY\n",
        "\n",
        "        # Only generate a new summary if there's enough new conversation\n",
        "        if len(MESSAGE_HISTORY) >= 2:\n",
        "            current_summary = generate_summary(MESSAGE_HISTORY)\n",
        "\n",
        "            if SUMMARY:\n",
        "                # Combine with previous summary\n",
        "                combined_prompt = f\"\"\"\n",
        "                Previous summary: {SUMMARY}\n",
        "\n",
        "                New conversation summary: {current_summary}\n",
        "\n",
        "                Please create a comprehensive summary that combines both:\"\"\"\n",
        "\n",
        "                try:\n",
        "                    response = client.chat.completions.create(\n",
        "                        model=CHAT_MODEL,\n",
        "                        messages=[{\"role\": \"user\", \"content\": combined_prompt}],\n",
        "                        max_tokens= 300,\n",
        "                        temperature=0.3\n",
        "                    )\n",
        "\n",
        "                    SUMMARY = response.choices[0].message.content.strip()\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"‚ùå Error combining summaries: {e}\")\n",
        "                    SUMMARY = current_summary\n",
        "            else:\n",
        "                SUMMARY = current_summary\n",
        "\n",
        "            # Replace history with summary\n",
        "            MESSAGE_HISTORY = [\n",
        "                {\"role\": \"system\", \"content\": CHAT_MODEL_SYSTEM_PROMPT},\n",
        "                {\"role\": \"system\", \"content\": f\"Previous conversation summary: {SUMMARY}\"}\n",
        "            ]\n",
        "\n",
        "            print(f\"Conversation summarized and history reset\")\n",
        "            print(f\"Current summary length: {len(SUMMARY)} characters\")"
      ],
      "metadata": {
        "id": "kkFgwJ8XezA2"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Helper Functions"
      ],
      "metadata": {
        "id": "TxuCIaXwGg1J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def count_words(text: str) -> int:\n",
        "    return len(text.split())\n",
        "\n",
        "def count_characters(messages: List[Dict]) -> int:\n",
        "    return sum(len(msg[\"content\"]) for msg in messages)\n",
        "\n",
        "def count_total_words(messages: List[Dict]) -> int:\n",
        "    return sum(count_words(msg[\"content\"]) for msg in messages)"
      ],
      "metadata": {
        "id": "LIu7myvAGgVv"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function to truncate conversation by turns"
      ],
      "metadata": {
        "id": "tnvwOw6CG5i-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_turns = 6\n",
        "def truncate_by_turns(messages: List[Dict]) -> List[Dict]:\n",
        "  if max_turns and len(messages) > max_turns:\n",
        "      truncated = messages[-max_turns:]\n",
        "      print(f\"Truncated to last {max_turns} messages\")\n",
        "      return truncated\n",
        "  return messages"
      ],
      "metadata": {
        "id": "pE0WOBZKHAua"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Truncate by length"
      ],
      "metadata": {
        "id": "K3yTmfOHID7k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_characters = 300\n",
        "max_words = 80\n",
        "def truncate_by_length(messages: List[Dict]) -> List[Dict]:\n",
        "    if not (max_characters or max_words):\n",
        "        return messages\n",
        "\n",
        "    result = []\n",
        "    current_chars = 0\n",
        "    current_words = 0\n",
        "\n",
        "    # Start from the end to keep most recent messages\n",
        "    for message in reversed(messages):\n",
        "        msg_chars = len(message[\"content\"])\n",
        "        msg_words = count_words(message[\"content\"])\n",
        "\n",
        "        # Check if adding this message would exceed limits\n",
        "        if (max_characters and current_chars + msg_chars > max_characters) or (max_words and current_words + msg_words > max_words):\n",
        "            break\n",
        "\n",
        "        result.insert(0, message)\n",
        "        current_chars += msg_chars\n",
        "        current_words += msg_words\n",
        "\n",
        "    if len(result) < len(messages):\n",
        "        removed = len(messages) - len(result)\n",
        "        print(f\"üìù Truncated {removed} messages due to length constraints\")\n",
        "\n",
        "    return result"
      ],
      "metadata": {
        "id": "7bbJJTIcIGaL"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get truncated history"
      ],
      "metadata": {
        "id": "Lo83zaogIyKV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_truncated_history(trunc_type:str) -> List[Dict]:\n",
        "        messages = MESSAGE_HISTORY.copy()\n",
        "        if not trunc_type:\n",
        "          raise ValueError(\"Truncation type not provided\")\n",
        "\n",
        "        # Apply truncation strategies\n",
        "        if trunc_type == \"turns\":\n",
        "          return truncate_by_turns(messages)\n",
        "\n",
        "        return truncate_by_length(messages)"
      ],
      "metadata": {
        "id": "MtFHLPzhI0c0"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get overall, used parameters"
      ],
      "metadata": {
        "id": "FBQf-HSCJ4Ws"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_statistics() -> Dict:\n",
        "    \"\"\"Get detailed statistics about the conversation.\"\"\"\n",
        "    stats = {\n",
        "            \"total_turns\": turn_count,\n",
        "            \"current_messages\": len(MESSAGE_HISTORY),\n",
        "            \"total_characters\": count_characters(MESSAGE_HISTORY),\n",
        "            \"total_words\": count_total_words(MESSAGE_HISTORY),\n",
        "            \"has_summary\": bool(SUMMARY),\n",
        "            \"summary_length\": len(SUMMARY) if SUMMARY else 0,\n",
        "            \"summarization_interval\": summarization_interval,\n",
        "            \"truncation_limits\": {\n",
        "                \"max_turns\": max_turns,\n",
        "                \"max_characters\": max_characters,\n",
        "                \"max_words\": max_words\n",
        "            }\n",
        "        }\n",
        "    return stats"
      ],
      "metadata": {
        "id": "_1LqAAA9J9dl"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_statistics()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7JOvYwVvKQQ7",
        "outputId": "c3b15e6c-96f6-4b3a-a151-0de9c8b9a8be"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'total_turns': 0,\n",
              " 'current_messages': 8,\n",
              " 'total_characters': 1676,\n",
              " 'total_words': 279,\n",
              " 'has_summary': True,\n",
              " 'summary_length': 969,\n",
              " 'summarization_interval': 8,\n",
              " 'truncation_limits': {'max_turns': 6, 'max_characters': 300, 'max_words': 80}}"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Test Bot**"
      ],
      "metadata": {
        "id": "p4pUiT_Sev_J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Try Conversation with LLM"
      ],
      "metadata": {
        "id": "3Yo043fbK0z5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "    user_input = input(\"User: \")\n",
        "    add_message({\"role\": \"user\", \"content\": user_input})\n",
        "\n",
        "    try:\n",
        "        chat_bot_response = client.chat.completions.create(\n",
        "            model=CHAT_MODEL,\n",
        "            messages=MESSAGE_HISTORY\n",
        "        )\n",
        "        response_content = chat_bot_response.choices[0].message.content\n",
        "        add_message({\"role\": \"assistant\", \"content\": response_content})\n",
        "\n",
        "        print(f\"Bot: {response_content}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")"
      ],
      "metadata": {
        "id": "kc8J6W-8R7-g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pbhqZoMjAM9Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test with test message jsons"
      ],
      "metadata": {
        "id": "hd7l3d_nK4Rt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "conversation_samples = [\n",
        "        (\"user\", \"Hello! I'm looking for advice on starting a small business.\"),\n",
        "        (\"assistant\", \"Great! I'd be happy to help. What type of business are you considering?\"),\n",
        "        (\"user\", \"I'm thinking about opening a coffee shop in downtown Seattle.\"),\n",
        "        (\"assistant\", \"Excellent choice! Seattle has a great coffee culture. Have you done any market research?\"),\n",
        "        (\"user\", \"Not yet. Where should I start with market research?\"),\n",
        "        (\"assistant\", \"I recommend starting with competitor analysis, foot traffic studies, and customer surveys.\"),\n",
        "        (\"user\", \"That sounds comprehensive. What about financing options?\"),\n",
        "        (\"assistant\", \"For coffee shops, you have several options: SBA loans, traditional bank loans, investors, or crowdfunding.\")\n",
        "    ]"
      ],
      "metadata": {
        "id": "Sv4vAGdYK_e0"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Clear previous history for a clean test\n",
        "MESSAGE_HISTORY = []\n",
        "turn_count = 0\n",
        "SUMMARY = \"\"\n",
        "\n",
        "print(\"--- Testing Truncation ---\")\n",
        "\n",
        "# fill message history with sample conversation\n",
        "for role, content in conversation_samples:\n",
        "    add_message({\"role\": role, \"content\": content})\n",
        "\n",
        "print(\"\\n--- Original Message History ---\")\n",
        "for msg in MESSAGE_HISTORY:\n",
        "    print(f\"{msg['role']}: {msg['content']}\")\n",
        "print(f\"Total messages: {len(MESSAGE_HISTORY)}\")\n",
        "\n",
        "print(\"\\n--- Truncating by Turns (max_turns=6) ---\")\n",
        "truncated_by_turns = get_truncated_history(trunc_type=\"turns\")\n",
        "for msg in truncated_by_turns:\n",
        "    print(f\"{msg['role']}: {msg['content']}\")\n",
        "print(f\"Truncated messages: {len(truncated_by_turns)}\")\n",
        "\n",
        "\n",
        "print(\"\\n--- Truncating by Length (max_characters=300, max_words=80) ---\")\n",
        "truncated_by_length = get_truncated_history(trunc_type=\"length\")\n",
        "for msg in truncated_by_length:\n",
        "    print(f\"{msg['role']}: {msg['content']}\")\n",
        "print(f\"Truncated messages: {len(truncated_by_length)}\")\n",
        "\n",
        "print(\"\\n--- Truncation Test Complete ---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E880Q_grLBj0",
        "outputId": "47cfd891-5259-4b33-a5b6-7a147cc8e3ff"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Testing Truncation ---\n",
            "Turn 1: Added {'role': 'user', 'content': \"Hello! I'm looking for advice on starting a small business.\"}\n",
            "Turn 2: Added {'role': 'assistant', 'content': \"Great! I'd be happy to help. What type of business are you considering?\"}\n",
            "Turn 3: Added {'role': 'user', 'content': \"I'm thinking about opening a coffee shop in downtown Seattle.\"}\n",
            "Turn 4: Added {'role': 'assistant', 'content': 'Excellent choice! Seattle has a great coffee culture. Have you done any market research?'}\n",
            "Turn 5: Added {'role': 'user', 'content': 'Not yet. Where should I start with market research?'}\n",
            "Turn 6: Added {'role': 'assistant', 'content': 'I recommend starting with competitor analysis, foot traffic studies, and customer surveys.'}\n",
            "Turn 7: Added {'role': 'user', 'content': 'That sounds comprehensive. What about financing options?'}\n",
            "Turn 8: Added {'role': 'assistant', 'content': 'For coffee shops, you have several options: SBA loans, traditional bank loans, investors, or crowdfunding.'}\n",
            "Turn count 8, output: 0\n",
            "‚úÖ Generated summary (615 characters)\n",
            "Conversation summarized and history reset\n",
            "Current summary length: 615 characters\n",
            "\n",
            "--- Original Message History ---\n",
            "system: \n",
            "\n",
            "\n",
            "system: Previous conversation summary: It's great that you're thinking about financing options early on. Additionally, you may also want to consider alternative lenders, small business grants, or even partnering with a business incubator. It's also important to create a solid business plan, including a detailed budget, revenue projections, and a marketing strategy. This will help you secure funding and make informed decisions as you move forward. \n",
            "\n",
            "Have you thought about what will set your coffee shop apart from the existing ones in downtown Seattle? What unique features, products, or services do you plan to offer to attract and retain customers?\n",
            "Total messages: 2\n",
            "\n",
            "--- Truncating by Turns (max_turns=6) ---\n",
            "system: \n",
            "\n",
            "\n",
            "system: Previous conversation summary: It's great that you're thinking about financing options early on. Additionally, you may also want to consider alternative lenders, small business grants, or even partnering with a business incubator. It's also important to create a solid business plan, including a detailed budget, revenue projections, and a marketing strategy. This will help you secure funding and make informed decisions as you move forward. \n",
            "\n",
            "Have you thought about what will set your coffee shop apart from the existing ones in downtown Seattle? What unique features, products, or services do you plan to offer to attract and retain customers?\n",
            "Truncated messages: 2\n",
            "\n",
            "--- Truncating by Length (max_characters=300, max_words=80) ---\n",
            "üìù Truncated 2 messages due to length constraints\n",
            "Truncated messages: 0\n",
            "\n",
            "--- Truncation Test Complete ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5tyL3Oq9LjQF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}